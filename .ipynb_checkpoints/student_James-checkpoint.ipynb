{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Submission\n",
    "\n",
    "Please fill out:\n",
    "* Student name: \n",
    "* Student pace: self paced / part time / full time\n",
    "* Scheduled project review date/time: \n",
    "* Instructor name: \n",
    "* Blog post URL:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing bs_ds.bs_ds on engine(s)\n",
      "importing bs_ds.bamboo on engine(s)\n"
     ]
    }
   ],
   "source": [
    "# Attempting multi-core processing\n",
    "import ipyparallel as ipp\n",
    "rc = ipp.Client()\n",
    "with rc[:].sync_imports():\n",
    "    import bs_ds.bs_ds as bs\n",
    "    import bs_ds.bamboo as bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rc.ids\n",
    "# dview=rc[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OSEMN Model\n",
    "1. **OBTAIN:**\n",
    "    - **Import data, inspect, check for datatypes to convert and null values**<br>\n",
    "        - Display header and info\n",
    "        - Drop any unneeded columns (df.drop(['col1','col2'],axis=1)\n",
    "\n",
    "2. **SCRUB: cast data types, identify outliers, check for multicollinearity, normalize data**<br>\n",
    "    - Check and cast data types\n",
    "        - [x] Check for #'s that are store as objects (df.info())\n",
    "            - when converting to #'s, look for odd values (like many 0's), or strings that can't be converted\n",
    "            - Decide how to deal weird/null values (df.unique(), df.isna().sum(), df.describe()-min/max, etc\n",
    "        - [x]  Check for categorical variables stored as integers\n",
    "    - [x] Check for missing values  (df.isna().sum())\n",
    "        - Can drop rows or colums\n",
    "        - For missing numeric data with median or bin/convert to categorical\n",
    "        - For missing categorical data: make NaN own category OR replace with most common category\n",
    "    - [x] Check for multicollinearity\n",
    "        - Good rule of thumb is anything over 0.75 corr is high, remove the variable that has the most correl with the largest # of variables\n",
    "    - [ ] Normalize data (may want to do after some exploring)\n",
    "        - Most popular is Z-scoring (but won't fix skew) \n",
    "        - Can log-transform to fix skewed data\n",
    "    \n",
    "            \n",
    "3. **EXPLORE:Check distributions, outliers, etc**\n",
    "    - [ ] Check scales, ranges (df.describe())\n",
    "    - [ ] Check histograms to get an idea of distributions (df.hist()) and dat transformations to perform\n",
    "        - Can also do kernel density estimates\n",
    "    - [ ] Use scatterplots to check for linearity and possible categorical variables (df.plot(kind-'scatter')\n",
    "        - categoricals will look like vertical lines\n",
    "    - [ ] Use pd.plotting.scatter_matrix to visualize possible relationships\n",
    "    - [ ] Check for linearity\n",
    "\n",
    "   \n",
    "4. **FIT AN INITIAL MODEL:** \n",
    "    - Various forms, detail later...\n",
    "    - **Assessing the model:**\n",
    "        - Assess parameters (slope,intercept)\n",
    "        - Check if the model explains the variation in the data (RMSE, F, R_square)\n",
    "        - *Are the coeffs, slopes, intercepts in appropriate units?*\n",
    "        - *Whats the impact of collinearity? Can we ignore?*\n",
    "5. **Revise the fitted model**\n",
    "    - Multicollinearity is big issue for lin regression and cannot fully remove it\n",
    "    - Use the predictive ability of model to test it (like R2 and RMSE)\n",
    "    - Check for missed non-linearity\n",
    "6. **Holdout validation / Train/test split**\n",
    "    - use sklearn train_test_split \n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs_ds.bamboo import *\n",
    "# import bs_ds as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_pandas()\n",
    "ignore_warnings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iowa Prisoner Recidivism Data\n",
    "\n",
    "- Source: https://www.kaggle.com/slonnadube/recidivism-for-offenders-released-from-prison\n",
    "- **Statistics about recidivism in prisoners from a 3 year prisoner**\n",
    "- **Target:**\n",
    "    - Recidivism - Return to Prison\n",
    "- **Features:**\n",
    "    - Fiscal Year Released\n",
    "    - Recidivism Reporting Year\n",
    "    - Race - Ethnicity\n",
    "    - Age At Release\n",
    "    - Convicting Offense Classification\n",
    "    - Convicting Offense Type\n",
    "    - Convicting Offense Subtype\n",
    "    - Main Supervising District\n",
    "    - Release Type\n",
    "    - Release type: Paroled to Detainder united\n",
    "    - Part of Target Population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From Kaggle Listing:**\n",
    ">For recidivism prediction the full dataset containing 26021 records was used. The name of the data set is: \"3-Year_Recidivism_for_Offenders_Released_from_Prison_in_Iowa_elaborated\". All the variables related to recidivism were excluded from the dataset, except the response variable: 'Recidivism - return to prison'. The response variable was turned into a numeric vector of (0,1), where 1 means 'yes recidivism' and 0 means 'no recidivism'. \n",
    "Other variables related to recidivism were of course not used in the predictive analysis. There are 26021 records in this dataset.\n",
    "\n",
    "> Another dataset was constructed using the initial one. This dataset is called 'prison_recidivists_with_recidivism_type_only'. It contains the records of those recidivists from the initial file for whom the type of recidivism has been recorded and documented.\n",
    "\n",
    "> This one done in order to enable the comparison between the seriousness of the initial offense and the type of recidivism. Therefore, only the records containing both types were left in this dataset, and the rest were filtered out. The second dataset containing data recidivists only is comprised of 6718 records."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-3-final-project-online-ds-ft-021119/master/districtmap09122014.jpg\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **The variables in the data set:**\n",
    "\n",
    "- Fiscal Year Released Fiscal year (year ending June 30) for which the offender was released from prison.\n",
    "\n",
    "- Recidivism Reporting Year \n",
    "    - Fiscal year (year ending June 30) that marks the end of the 3-year tracking period. For example, offenders exited prison in FY 2012 are found in recidivism reporting year FY 2015.\n",
    "\n",
    "- Race - Ethnicity \n",
    "    - Offender's Race and Ethnicity\n",
    "\n",
    "- Convicting Offense Classification \n",
    "    - Maximum penalties: A Felony = Life; B Felony = 25 or 50 years; C Felony = 10 years; D Felony = 5 years; Aggravated Misdemeanor = 2 years; Serious Misdemeanor = 1 year; Simple Misdemeanor = 30 days\n",
    "\n",
    "- Convicting Offense Type General category for the most serious offense for which the offender was placed in prison.\n",
    "\n",
    "- Convicting Offense Subtype \n",
    "    - Further classification of the most serious offense for which the offender was placed in prison.\n",
    "\n",
    "- Release Type \n",
    "    - Reasoning for Offender's release from prison.\n",
    "\n",
    "- Main Supervising District \n",
    "    - The Judicial District supervising the offender for the longest time during the tracking period.\n",
    "\n",
    "- Recidivism - Return to Prison \n",
    "    - No = No Recidivism; Yes = Prison admission for any reason within the 3-year tracking period\n",
    "\n",
    "- Days to Recidivism \n",
    "    - Number of days it took before the offender returned to prison.\n",
    "\n",
    "- New Conviction Offense Classification The same as the initial offense classification.\n",
    "\n",
    "- New Conviction Offense Type The same as the initial offense type.\n",
    "\n",
    "- New Conviction Offense Sub Type The same as the initial offense subtype.\n",
    "\n",
    "- Part of Target Population \n",
    "    - The Department of Corrections has undertaken specific strategies to reduce recidivism rates for prisoners who are on parole and are part of the target population.\n",
    "    ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing custom-library of functions.\n",
    "# from bs_ds.bamboo import *\n",
    "import bs_ds\n",
    "from bs_ds.imports import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Links\n",
    "# all_prisoners_url = 'https://raw.githubusercontent.com/jirvingphd/dsc-3-final-project-online-ds-ft-021119/master/dataset/3-Year_Recidivism_for_Offenders_Released_from_Prison_in_Iowa_elaborated.csv'\n",
    "all_prisoners_file = \"datasets/3-Year_Recidivism_for_Offenders_Released_from_Prison_in_Iowa_elaborated.csv\"\n",
    "full_all_prisoners_file = \"datasets/FULL_3-Year_Recidivism_for_Offenders_Released_from_Prison_in_Iowa.csv\"\n",
    "# only_repeat_criminals_w_new_crime_url = \"https://raw.githubusercontent.com/jirvingphd/dsc-3-final-project-online-ds-ft-021119/master/dataset/prison_recidivists_with_recidivism_type_only.csv\"\n",
    "only_repeat_criminals_w_new_crime_file= \"datasets/prison_recidivists_with_recidivism_type_only.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will be using the all_prisoners file to predict recidivism\n",
    "df = pd.read_csv(full_all_prisoners_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs_ds.bamboo import inspect_df, check_null, check_unique, check_column, check_numeric\n",
    "inspect_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Any columns that are about New Convictions or days to recidivism should be dropped for our initial model predicting recidivism.**\n",
    "- \"New..\", \"Days to Recividism\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs_ds.bamboo import drop_cols\n",
    "df = drop_cols(df, ['New','Days','Recidivism Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save original names vs short names in column_legend\n",
    "- then map names onto columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames_orig = df.columns\n",
    "colnames_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames_short = ('yr_released','report_year','race_ethnicity','age_released','crime_class','crime_type','crime_subtype','release_type','super_dist','recidivist','target_pop','sex')\n",
    "\n",
    "column_legend = dict(zip(colnames_orig,colnames_short))\n",
    "column_legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename df with shorter names\n",
    "df.rename(mapper=column_legend,axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigating Values for Each Object Column and Determining How to Handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADDRESSING NULL VALUES\n",
    "### Checking Null Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_null(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results of Null Check**\n",
    "- race_ethnicity has 30 (0.12% of data)\n",
    "    -  drop\n",
    "- age_at_release has 3 (0.01% of data)\n",
    "    - drop\n",
    "- sex has 3 (0.01% of data)\n",
    "    - drop\n",
    "- super_district has 9581(36.82% of data)\n",
    "    - replace\n",
    "    - with...\n",
    "- release_type has 1762 (6.77% of data)\n",
    "    - replace\n",
    "    - with\n",
    "- part_target_pop has 1762 (6.77% of data)\n",
    "    - replace\n",
    "    - with...\n",
    "    \n",
    "### Checking Columns with Nulls to Replace to Decide Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping null values from 'age_at_release','race_ethnicity'\n",
    "df.dropna(subset=['age_released','race_ethnicity','sex'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_null(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results of Null Check**\n",
    "- super_district has 9549(36.75% of data)\n",
    "    - replace\n",
    "    - with 'unknown'\n",
    "- release_type has 1762 (6.78% of data)\n",
    "    - replace  (_could_ consider dropping)\n",
    "    - with 'unknown'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_unique(df, columns=['super_dist','release_type']) #,'target_pop','crime_type','crime_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling NA's in super_dist and release_type\n",
    "df.fillna(\"unknown\",inplace=True)\n",
    "\n",
    "check_null(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining how to handle/encode features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_unique(df,['crime_class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes on columns\n",
    "- Numeric:\n",
    "    - yr_release\n",
    "    - recid_report_yr\n",
    "- Ordinal:\n",
    "    - age_at_release should be an ordinal label.\n",
    "- All others should be LabelEncoded\n",
    "    - class_of_crime\n",
    "    - crime_type\n",
    "    - crime_subtype\n",
    "    - super_district\n",
    "    - release_type\n",
    "    - part_target_pop\n",
    "    - ~~recidivism~~ (have 'recid_code')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_legend.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lists of Vars to encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining lists to use later.\n",
    "vars_label_encode = ['race_ethnicity','crime_class','crime_type', 'crime_subtype', 'super_dist', 'release_type', 'target_pop', 'sex','age_released','recidivist']\n",
    "# vars_ord_encode = ['age_released']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting categorical variables to category type before encoding\n",
    "~~Encoding age_at_release as Ordinal~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_unique(df,['recidivist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['recidivist']=df['recidivist'].map({'No':0,'Yes':1});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_unique(df,['recidivist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in vars_label_encode:\n",
    "    df[col] = df[col].astype('category')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding age_at_release by mapping a dictionary onto the columns instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordering age categories in a tuple and then turning into an array.\n",
    "cat_codes = ('Under 25','25-34', '35-44','45-54','55 and Older')\n",
    "cat_codes = np.array(cat_codes)\n",
    "cat_codes\n",
    "# Defining age range tuple\n",
    "age_range = tuple(cat_codes)\n",
    "age_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining age_code type\n",
    "age_codes = (0,1,2,3,4)\n",
    "\n",
    "# Zipping into Dictionary to Map onto Column\n",
    "age_map = dict(zip(age_range,age_codes))\n",
    "age_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_code['age_code'] = df_code['age_at_release'].map(age_map)\n",
    "# # check_unique(df_code,['age_at_release','age_code']) #df_code['age_code'].value_counts()\n",
    "# df_code.drop('age_at_release',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categorical columns using LabelLibrary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs_ds.bamboo import LabelLibrary\n",
    "lablib = LabelLibrary()\n",
    "df_code = lablib.fit_transform(df,vars_label_encode)\n",
    "\n",
    "df_code.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_code.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bs_ds.bamboo import plot_hist_scat\n",
    "plot_hist_scat(df_code,'recidivist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from bs_ds.bamboo import multiplot\n",
    "multiplot(df_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments on Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Everything looks good to go with the possible exception of recivisidm_year. \n",
    "- Keeping for now. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(df.drop('recidivist',axis=1))\n",
    "y = df.recidivist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X.to_csv('X_one_hot_05072019_0815pm.csv')\n",
    "# X = pd.read_csv('X_one_hot_05072019_0815pm.csv')\n",
    "# y= pd.read_csv('y_recidivist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y.to_csv('y_recidivist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs_ds.bs_ds import scale_data, thick_pipe, compare_pipes, make_config_dict,make_random_config_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using bs_ds.bs_ds.thick_pipe \n",
    "1. Try scaling the features with different scalers for improves results\n",
    "2. Use highest score to determine which models to try first.\n",
    "2B. Test parameters compare_pipes using search = 'random', get best estimators from it\n",
    "- When find the best parameters, use those to zero in on a smaller range to test again with compare pipes with smaller ranges of parameters\n",
    "- Some of the models that are more computatinally intensive that may want to be tested in small batches or 1 at a time:\n",
    "    - LogRegCV, XGB, GradBoost, AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hot = pd.get_dummies(df.drop(['recidivist','yr_released','report_year'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_hot\n",
    "y = df_code['recidivist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%px pipe_res = bs.thick_pipe(X,y,verbose=False);\n",
    "# pipe_res = thick_pipe(X,y,verbose=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Notes on thick pipe run # 1(ish)\n",
    "    - Very similar results for most models(except dectree, randomfor)\n",
    "    - Best score is 0.0.68 gradboost\n",
    "- Notes on run # 2 (one-hot encoded everything but years and target)\n",
    "    - Basically same performance, but xgb eeks out .6782\n",
    "    \n",
    "| ---- | ---- | ---- |\n",
    "|0\tLogReg: 0.6779|,1\tSVC:\t0.6698, 2\tDecTree:\t0.6318, 3\tRandFor:\t0.6391, 4\tAdaBoost:\t0.6697, 5\tGradBoost:\t0.6780, 6\txgb\t0.6782"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=[] # freeing up memory \n",
    "for col in vars_label_encode:\n",
    "    df_code[col] = df_code[col].astype('category')\n",
    "df_code.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From prior days:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info(), y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree_clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgb = xgboost.sklearn.XGBClassifier()\n",
    "clf_gbc = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params={'max_depth':10}\n",
    "tree_clf.set_params(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf.feature_importances_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importances(model):\n",
    "    n_features = X_train.shape[1]\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center') \n",
    "    plt.yticks(np.arange(n_features), X_train.columns.values) \n",
    "    plt.xlabel(\"Feature importance\")\n",
    "    plt.ylabel(\"Feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('C:\\\\Program\\ Files\\ \\(x86\\)\\\\Graphviz2.38\\\\bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs_ds import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "viz_tree(tree_clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(tree_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessing Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = tree_clf.predict(X_test)\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test, pred))\n",
    "print(accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagged Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "bagged_tree = BaggingClassifier(DecisionTreeClassifier(criterion='gini',max_depth=5), n_estimators=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagged_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagged_tree.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bagged_tree.predict(X_test)\n",
    "bagged_tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100, max_depth=5)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(forest.score(X_train, y_train))\n",
    "print(forest.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env-ext",
   "language": "python",
   "name": "learn-env-ext"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 572.391,
   "position": {
    "height": "594.391px",
    "left": "838.6px",
    "right": "20px",
    "top": "70px",
    "width": "705.391px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
