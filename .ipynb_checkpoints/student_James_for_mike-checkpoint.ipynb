{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Submission\n",
    "\n",
    "Please fill out:\n",
    "* Student name: \n",
    "* Student pace: self paced / part time / full time\n",
    "* Scheduled project review date/time: \n",
    "* Instructor name: \n",
    "* Blog post URL:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iowa Prisoner Recidivism Data\n",
    "\n",
    "- Source: https://www.kaggle.com/slonnadube/recidivism-for-offenders-released-from-prison\n",
    "- **Statistics about recidivism in prisoners from a 3 year prisoner**\n",
    "- **Target:**\n",
    "    - Recidivism - Return to Prison\n",
    "- **Features:**\n",
    "    - Fiscal Year Released\n",
    "    - Recidivism Reporting Year\n",
    "    - Race - Ethnicity\n",
    "    - Age At Release\n",
    "    - Convicting Offense Classification\n",
    "    - Convicting Offense Type\n",
    "    - Convicting Offense Subtype\n",
    "    - Main Supervising District\n",
    "    - Release Type\n",
    "    - Release type: Paroled to Detainder united\n",
    "    - Part of Target Population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OSEMN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **OBTAIN:**\n",
    "    - **Import data, inspect, check for datatypes to convert and null values**<br>\n",
    "        - Display header and info\n",
    "        - Drop any unneeded columns (df.drop(['col1','col2'],axis=1)\n",
    "\n",
    "2. **SCRUB: cast data types, identify outliers, check for multicollinearity, normalize data**<br>\n",
    "    - Check and cast data types\n",
    "        - [x] Check for #'s that are store as objects (df.info())\n",
    "            - when converting to #'s, look for odd values (like many 0's), or strings that can't be converted\n",
    "            - Decide how to deal weird/null values (df.unique(), df.isna().sum(), df.describe()-min/max, etc\n",
    "        - [x]  Check for categorical variables stored as integers\n",
    "    - [x] Check for missing values  (df.isna().sum())\n",
    "        - Can drop rows or colums\n",
    "        - For missing numeric data with median or bin/convert to categorical\n",
    "        - For missing categorical data: make NaN own category OR replace with most common category\n",
    "    - [x] Check for multicollinearity\n",
    "        - Good rule of thumb is anything over 0.75 corr is high, remove the variable that has the most correl with the largest # of variables\n",
    "    - [ ] Normalize data (may want to do after some exploring)\n",
    "        - Most popular is Z-scoring (but won't fix skew) \n",
    "        - Can log-transform to fix skewed data\n",
    "    \n",
    "            \n",
    "3. **EXPLORE:Check distributions, outliers, etc**\n",
    "    - [ ] Check scales, ranges (df.describe())\n",
    "    - [ ] Check histograms to get an idea of distributions (df.hist()) and dat transformations to perform\n",
    "        - Can also do kernel density estimates\n",
    "    - [ ] Use scatterplots to check for linearity and possible categorical variables (df.plot(kind-'scatter')\n",
    "        - categoricals will look like vertical lines\n",
    "    - [ ] Use pd.plotting.scatter_matrix to visualize possible relationships\n",
    "    - [ ] Check for linearity\n",
    "\n",
    "   \n",
    "4. **FIT AN INITIAL MODEL:** \n",
    "    - Various forms, detail later...\n",
    "    - **Assessing the model:**\n",
    "        - Assess parameters (slope,intercept)\n",
    "        - Check if the model explains the variation in the data (RMSE, F, R_square)\n",
    "        - *Are the coeffs, slopes, intercepts in appropriate units?*\n",
    "        - *Whats the impact of collinearity? Can we ignore?*\n",
    "5. **Revise the fitted model**\n",
    "    - Multicollinearity is big issue for lin regression and cannot fully remove it\n",
    "    - Use the predictive ability of model to test it (like R2 and RMSE)\n",
    "    - Check for missed non-linearity\n",
    "6. **Holdout validation / Train/test split**\n",
    "    - use sklearn train_test_split \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/jirvingphd/dsc-3-final-project-online-ds-ft-021119/master/districtmap09122014.jpg\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **The variables in the data set:**\n",
    "\n",
    "- Fiscal Year Released Fiscal year (year ending June 30) for which the offender was released from prison.\n",
    "\n",
    "- Recidivism Reporting Year \n",
    "    - Fiscal year (year ending June 30) that marks the end of the 3-year tracking period. For example, offenders exited prison in FY 2012 are found in recidivism reporting year FY 2015.\n",
    "\n",
    "- Race - Ethnicity \n",
    "    - Offender's Race and Ethnicity\n",
    "\n",
    "- Convicting Offense Classification \n",
    "    - Maximum penalties: A Felony = Life; B Felony = 25 or 50 years; C Felony = 10 years; D Felony = 5 years; Aggravated Misdemeanor = 2 years; Serious Misdemeanor = 1 year; Simple Misdemeanor = 30 days\n",
    "\n",
    "- Convicting Offense Type General category for the most serious offense for which the offender was placed in prison.\n",
    "\n",
    "- Convicting Offense Subtype \n",
    "    - Further classification of the most serious offense for which the offender was placed in prison.\n",
    "\n",
    "- Release Type \n",
    "    - Reasoning for Offender's release from prison.\n",
    "\n",
    "- Main Supervising District \n",
    "    - The Judicial District supervising the offender for the longest time during the tracking period.\n",
    "\n",
    "- Recidivism - Return to Prison \n",
    "    - No = No Recidivism; Yes = Prison admission for any reason within the 3-year tracking period\n",
    "\n",
    "- Days to Recidivism \n",
    "    - Number of days it took before the offender returned to prison.\n",
    "\n",
    "- New Conviction Offense Classification The same as the initial offense classification.\n",
    "\n",
    "- New Conviction Offense Type The same as the initial offense type.\n",
    "\n",
    "- New Conviction Offense Sub Type The same as the initial offense subtype.\n",
    "\n",
    "- Part of Target Population \n",
    "    - The Department of Corrections has undertaken specific strategies to reduce recidivism rates for prisoners who are on parole and are part of the target population.\n",
    "    ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Packages and Loading in the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import custom python package BroadSteel DataScience (bs_ds_)\n",
    "from bs_ds.imports import *\n",
    "from bs_ds.bamboo import inspect_df, check_null, check_unique, check_column, check_numeric, big_pandas, ignore_warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Enabling full-sized dataframes and info rows\n",
    "big_pandas()\n",
    "\n",
    "# Turning off warnings for function deprecations\n",
    "ignore_warnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Links\n",
    "# mike_csv ='3-Year_Recidivism_for_Offenders_Released_from_Prison_in_Iowa.csv'\n",
    "# mike_csv = 'No_numbers.csv'\n",
    "# mike_enhanced_df = 'Updated_class.csv'\n",
    "\n",
    "# all_prisoners_url = 'https://raw.githubusercontent.com/jirvingphd/dsc-3-final-project-online-ds-ft-021119/master/dataset/3-Year_Recidivism_for_Offenders_Released_from_Prison_in_Iowa_elaborated.csv'\n",
    "# all_prisoners_file = \"datasets/3-Year_Recidivism_for_Offenders_Released_from_Prison_in_Iowa_elaborated.csv\"\n",
    "full_all_prisoners_file = \"datasets/FULL_3-Year_Recidivism_for_Offenders_Released_from_Prison_in_Iowa.csv\"\n",
    "# only_repeat_criminals_w_new_crime_url = \"https://raw.githubusercontent.com/jirvingphd/dsc-3-final-project-online-ds-ft-021119/master/dataset/prison_recidivists_with_recidivism_type_only.csv\"\n",
    "only_repeat_criminals_w_new_crime_file= \"datasets/prison_recidivists_with_recidivism_type_only.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will be using the all_prisoners file to predict recidivism\n",
    "df = pd.read_csv(full_all_prisoners_file)\n",
    "# df_enhanced_col = pd.read_csv(mike_enhanced_df, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_enhanced_col.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inspect_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Any columns that are about New Convictions or days to recidivism should be dropped for our initial model predicting recidivism.**\n",
    "- \"New..\", \"Days to Recividism\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs_ds.bamboo import drop_cols\n",
    "df = drop_cols(df, ['New','Days','Recidivism Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save original names vs short names in column_legend\n",
    "- then map names onto columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New short-hand names to use\n",
    "colnames_short = ('yr_released','report_year','race_ethnicity','age_released','crime_class','crime_type','crime_subtype','release_type','super_dist','recidivist','target_pop','sex')\n",
    "\n",
    "# Zipping the original and new into a renaming dictionary\n",
    "column_legend = dict(zip(df.columns,colnames_short))\n",
    "# Rename df with shorter names\n",
    "df.rename(mapper=column_legend, axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADDRESSING NULL VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_null(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results of Null Check**\n",
    "- race_ethnicity has 30 (0.12% of data)\n",
    "    -  drop\n",
    "- age_released has 3 (0.01% of data)\n",
    "    - drop\n",
    "- sex has 3 (0.01% of data)\n",
    "    - drop\n",
    "- super_district has 9581(36.82% of data)\n",
    "    - replace\n",
    "    - with...\n",
    "- release_type has 1762 (6.77% of data)\n",
    "    - drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Dropping all null values from age_released, race_ethnicity, and release_type.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping null values from 'age_at_release','race_ethnicity'\n",
    "# df.dropna(subset=['age_released','race_ethnicity','sex','release_type'],inplace=True)\n",
    "\n",
    "# pause\n",
    "# For mike's data\n",
    "# df['super_dist'].fillna(\"unknown\", inplace=True)\n",
    "# df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_null(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results of Null Check**\n",
    "- super_district has 9549(36.75% of data)\n",
    "    - replace\n",
    "    - with 'unknown'\n",
    "- release_type has 1762 (6.78% of data)\n",
    "    - replace  (_could_ consider dropping)\n",
    "    - with 'unknown'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigating values of classes with large # of NaN's\n",
    "check_unique(df, columns=['super_dist']) #,'target_pop','crime_type','crime_class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Filling super_dist NaNs with \"unknown\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling NA's in super_dist and release_type\n",
    "df['super_dist'].fillna(\"unknown\", inplace=True)\n",
    "check_null(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMBINING AND REMAPPING CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Remapping race_ethnicity**\n",
    "    - Going to combine hispanic and non-hispanic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remapping race_ethnicity\n",
    "race_ethnicity_map = {'White - Non-Hispanic':'White',\n",
    "                        'Black - Non-Hispanic': 'Black',\n",
    "                        'White - Hispanic' : 'Hispanic',\n",
    "                        'American Indian or Alaska Native - Non-Hispanic' : 'American Native',\n",
    "                        'Asian or Pacific Islander - Non-Hispanic' : 'Asian or Pacific Islander',\n",
    "                        'Black - Hispanic' : 'Black',\n",
    "                        'American Indian or Alaska Native - Hispanic':'American Native',\n",
    "                        'White -' : 'White',\n",
    "                        'Asian or Pacific Islander - Hispanic' : 'Asian or Pacific Islander',\n",
    "                        'N/A -' : np.nan,\n",
    "                        'Black -':'Black'}\n",
    "df['race_ethnicity'] = df['race_ethnicity'].map(race_ethnicity_map)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Remapping crime_class**\n",
    "    - Combine 'Other Felony' and 'Other Felony (Old Code)' -> nan\n",
    "    - Other Misdemeanor -> np.nan\n",
    "    - Felony - Mandatory Minimum -> np.nan\n",
    "    - Special Sentence 2005 -> Sex Offender\n",
    "    - 'Sexual Predator Community Supervision' -> 'Sex Offender'\n",
    "    - Other Felony -> np.nan    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_class_map = {'Other Felony (Old Code)': np.nan ,#or other felony\n",
    "                  'Other Misdemeanor':np.nan,\n",
    "                   'Felony - Mandatory Minimum':np.nan, # if minimum then lowest sentence ==  D Felony\n",
    "                   'Special Sentence 2005': 'Sex Offender',\n",
    "                   'Other Felony' : np.nan ,\n",
    "                   'Sexual Predator Community Supervision' : 'Sex Offender',\n",
    "                   'D Felony': 'D Felony',\n",
    "                   'C Felony' :'C Felony',\n",
    "                   'B Felony' : 'B Felony',\n",
    "                   'A Felony' : 'A Felony',\n",
    "                   'Aggravated Misdemeanor':'Aggravated Misdemeanor',\n",
    "                   'Felony - Enhancement to Original Penalty':'Felony - Enhanced',\n",
    "                   'Felony - Enhanced':'Felony - Enhanced' ,\n",
    "                   'Serious Misdemeanor':'Serious Misdemeanor',\n",
    "                   'Simple Misdemeanor':'Simple Misdemeanor'}\n",
    "\n",
    "df['crime_class'] = df['crime_class'].map(crime_class_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Encoding age groups as ordinal**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding age groups as ordinal\n",
    "age_ranges = ('Under 25','25-34', '35-44','45-54','55 and Older')\n",
    "age_codes = (0,1,2,3,4) \n",
    "# Zipping into Dictionary to Map onto Column\n",
    "age_map = dict(zip(age_ranges,age_codes))\n",
    "\n",
    "# Mapping age_map onto 'age_released'\n",
    "df['age_released'] = df['age_released'].map(age_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Remapping binary categories ( recidivist, target_pop, sex)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remapping binary categories\n",
    "\n",
    "# Recidivist\n",
    "recidivist_map = {'No':0,'Yes':1}\n",
    "df['recidivist'] = df['recidivist'].map(recidivist_map)\n",
    "\n",
    "# Target_pop\n",
    "target_pop_map = {'No':0,'Yes':1}\n",
    "df['target_pop'] = df['target_pop'].map(target_pop_map)\n",
    "\n",
    "#sex_map\n",
    "sex_map = {'Male':0,'Female':1}\n",
    "df['sex'] = df['sex'].map(sex_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remapping release_type\n",
    "**DECIDED NOT TO SINCE THIS COULD BE AN IMPORTANT LEVEL OF NUANCE**\n",
    "- Combine Parole Grant and Parole and Paroled w/ Immediate Discharge [?]\n",
    "- Combine Discharged - End of Sentence and Discharged - Expiration of Sentence\n",
    "- **unknown...?** (keeping but consider dropping\n",
    "- Combine Released to Special Sentence and Special Sentence\n",
    "- Combine Paroled to Detainer - Out of State, Paroled to Detainer - INS, Paroled to Detainer - U.S. Marshall, Paroled to Detainer - Iowa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "release_type_map = {'Parole': 'Paroled',\n",
    "                    'Discharged – End of Sentence': 'Discharged - End of Sentence',\n",
    "                    'Special Sentence':'Special Sentence',\n",
    "                    'Parole Granted': 'Paroled',\n",
    "                    'Discharged - Expiration of Sentence' : 'Discharged - End of Sentence',\n",
    "                    'Paroled w/Immediate Discharge': 'Paroled',\n",
    "                    'Paroled to Detainer - Iowa':'Paroled to Detainer',\n",
    "                    'Paroled to Detainer - U.S. Marshall':'Paroled to Detainer',\n",
    "                    'Paroled to Detainer - Out of State':'Paroled to Detainer',\n",
    "                    'Released to Special Sentence':'Special Sentence',\n",
    "                    'Paroled to Detainer - INS':'Paroled to Detainer',\n",
    "                    'unknown':np.nan}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['release_type_map'] = df['release_type'].map(release_type_map)\n",
    "df['release_type_map'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engineering Features\n",
    "- **Engineering a simple 'felony' true false category**\n",
    "- **Combining crime_type and crime_subtype into types_combined**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engineering a simple 'felony' true false category\n",
    "df['felony'] = df['crime_class'].str.contains('felony',case=False)\n",
    "df['crime_types_combined'] = df['crime_type']+'_'+df['crime_subtype']\n",
    "# Combining crime_type and crime_subtype into types_combined\n",
    "df['crime_class_type_subtype']= df['crime_class']+'_'+df['crime_type']+'_'+df['crime_subtype']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Creating a 'max_sentence' feature based on crime class**\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping years onto crime class\n",
    "crime_class_max_sentence_map = {'A Felony': 75,  # Life\n",
    "                                'Aggravated Misdemeanor': 2, # 2 years\n",
    "                                'B Felony': 50, # 25 or 50 years\n",
    "                                'C Felony': 10, # 10 years\n",
    "                                'D Felony': 5,  # 5 yeras\n",
    "                                'Felony - Enhanced': 10, # Add on to class C and D felonies, hard to approximate. \n",
    "                                'Serious Misdemeanor': 1, # 1 year\n",
    "                                'Sex Offender': 10, # 10 years\n",
    "                                'Simple Misdemeanor': 0.83} # 30 days\n",
    "\n",
    "# Mapping max_sentence_column\n",
    "df['max_sentence'] =df['crime_class'].map(crime_class_max_sentence_map)\n",
    "# df['max_sentence'].value_counts().sort_index()\n",
    "\n",
    "# Display new value counts\n",
    "for col in ['recidivist','target_pop','sex']:\n",
    "    print(f\"{col} value counts:\\n {df[col].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping all  values replaced with np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "check_null(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv('iowa_recidivism_df_with_james_features_all_rows.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "check_null(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## effectml.com using grid search to optimize catbost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_cols = ['yr_released','race_ethnicity',\n",
    "                 'crime_class','release_type','crime_type','crime_subtype',\n",
    "                 'target_pop','sex','super_dist','felony','release_type'] #,'release_type_map','crime_class_type_subtype',]\n",
    "number_cols = ['max_sentence','age_released']\n",
    "target_col = ['recidivist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "df_to_split=pd.DataFrame()\n",
    "#adding in scaling for numeric data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sca = MinMaxScaler()\n",
    "\n",
    "for header in number_cols:\n",
    "    print(header)\n",
    "    data = np.array(df[header])\n",
    "    res = sca.fit_transform(data.reshape(-1,1))\n",
    "    df_to_split[header] = res.ravel()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categoryies to codes\n",
    "for header in category_cols:\n",
    "    df_to_split[header] = df[header].astype('category').cat.codes\n",
    "    \n",
    "# df_to_split=pd.concat([df_to_split, df[number_cols]],axis=1)\n",
    "df_to_split.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add in smote to balance out the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_unique(df_to_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_to_split\n",
    "y = pd.Series(df[target_col].to_numpy().ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "print(pd.Series(y).value_counts())\n",
    "X_resampled, y_resampled = SMOTE().fit_sample(X,y)\n",
    "print(pd.Series(y_resampled).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled =pd.DataFrame(X_resampled, columns = X.columns)\n",
    "y_resampled =pd.Series(y_resampled)\n",
    "y_resampled.name ='recidivist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect_df(X_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert X_resampled columns backt o int\n",
    "for header in category_cols:\n",
    "    X_resampled[header] = X_resampled[header].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_resampled.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using CatBoostClassifier and Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import Pool, CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(df_to_split, df[target_col])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pool =  Pool(data=X_train, label=y_train, cat_features=category_cols)\n",
    "test_pool = Pool(data=X_test, label=y_test,  cat_features=category_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cb_clf = CatBoostClassifier(iterations=3000, depth=12, boosting_type='Ordered', learning_rate=0.01,thread_count=-1,eval_metric='AUC', silent=True, allow_const_label=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cb_clf.fit(train_pool,eval_set=test_pool, plot=True, early_stopping_rounds=20)\n",
    "cb_clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________________________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env-ext",
   "language": "python",
   "name": "learn-env-ext"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 572.166222,
   "position": {
    "height": "40px",
    "left": "841.588px",
    "right": "20px",
    "top": "77px",
    "width": "705.319px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
